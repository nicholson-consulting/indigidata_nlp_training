{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting text\n",
    "This notebook includes the code necessary to collect text data and to process it\n",
    "in such a way that we can use it for our NLP exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \"Māori Names\" text data\n",
    "\n",
    "We're going to grab a dubious list of \"Maori names\" from a website that doesn't\n",
    "seem to have any concept of Māori data sovereignty or concerns about cultural appropriation:\n",
    "`https://momlovesbest.com/maori-names`\n",
    "\n",
    "We'll convert this data to a list of tuples of the form `('name', 'gender')` and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import selenium to load content from the dynamic website\n",
    "# Import BeautifulSoup4 to process the html\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Grab the webpage content via starting a browser\n",
    "browser = webdriver.Chrome()\n",
    "browser.get(\"https://momlovesbest.com/maori-names\")\n",
    "body = browser.find_element(By.TAG_NAME, 'body')\n",
    "\n",
    "# need to move around on the page a bit to force content to load\n",
    "body.send_keys(Keys.END)\n",
    "body.send_keys(Keys.PAGE_UP)\n",
    "time.sleep(3)\n",
    "\n",
    "# now grab all the html from the page and close the browser\n",
    "html = browser.page_source\n",
    "browser.quit()\n",
    "\n",
    "# pull the name and gender records from the html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "divs = soup.find_all('div', class_='name-list' )\n",
    "\n",
    "# map boy->male and girl->female to match name data from other sources\n",
    "map_name_gender = {'boy':'male', 'girl':'female', 'unisex':'unisex'}\n",
    "name_list = []\n",
    "\n",
    "# iterate through the list of all the `div` sections and get the names and genders\n",
    "# map the genders from boy/girl to male/female\n",
    "for div in divs:\n",
    "  name = div.get('data-name')\n",
    "  gender = div.get('data-gender')\n",
    "  name_list.append((name, map_name_gender[gender]))\n",
    "\n",
    "print(name_list[:3]) #print the first few tagged names\n",
    "\n",
    "# write the list of ('name', 'gender') tuples as a text file that we can use later\n",
    "with open('maoriNames.txt','w') as f:\n",
    "  for item in name_list:\n",
    "    f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermission - defining a function for later use\n",
    "In the next couple of sections we're going to want to repeat the same task a couple of times - \n",
    "pulling text out of a PDF document, tokenizing it as words, cleaning it up a bit and then tagging the words.\n",
    "We'll write a function that we can re-use for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextAndTagIt(pdfPath, tag):\n",
    "  # pdfPath should be the path to the PDF doc that we're going to pull text from\n",
    "  # tag should be a string that we want to tag all the words in the text with\n",
    "  from PyPDF2 import PdfReader\n",
    "  reader = PdfReader(pdfPath)\n",
    "\n",
    "  # get all the text from all the pages\n",
    "  text = \" \"\n",
    "  for pageNum in range(len(reader.pages)):\n",
    "    text += reader.pages[pageNum].extract_text()\n",
    "  textList = text.split() #tokenize on whitespace\n",
    "\n",
    "  # do some quick and dirty cleaning by stripping punctuation and numbers at the start/end of words\n",
    "  # then get the set of unique words\n",
    "  textList = [word.strip('0123456789$?!()/%,.;-<>') for word in textList]\n",
    "  textList = set(textList)\n",
    "  taggedText = [(word, tag) for word in textList if not word==\"\"]\n",
    "\n",
    "  print(\"Extracted\",len(textList),\"unique words from\",pdfPath,\n",
    "        \"\\nTagged them all as\", tag)\n",
    "  print(taggedText[:3])\n",
    "\n",
    "  return taggedText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kupu Māori text data\n",
    "\n",
    "In the next section we're going to process some text data from a PDF report that's entirely\n",
    "in te reo Māori. \n",
    "\n",
    "The report comes from `https://www.tematawai.maori.nz/assets/Corporate-Documents/WEB3-Singles-Te-Matawai-Annual-Report-22-23-Maori-v9.pdf` but we've dropped some of the title pages to get to the text-heavy sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text, tag it\n",
    "taggedKupu = getTextAndTagIt(\"teMatawai.pdf\", \"maori\")\n",
    "\n",
    "# save the tagged text to file\n",
    "with open('kupuMaori.txt', 'w', encoding='utf8') as f:\n",
    "  for item in taggedKupu:\n",
    "    f.write(f\"{item}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting list of tagged words isn't perfect. This is because there are some\n",
    "kupu in the input data (like names of institutions and web addresses) that mean\n",
    "we still have English kupu like 'Limited' in our corpus that have been tagged as 'Māori'.\n",
    "\n",
    "We won't worry too much about trying to fix all of these here. But it's worth thinking\n",
    "about how inaccuracies like these might manifest in the classifier training that we \n",
    "will be doing later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kupu Pakeha text data\n",
    "\n",
    "Now we're going to follow the same process as above but to get a corpus of Pakeha words and to tag them.\n",
    "(If we wanted to, we could just use an English corpus from the NLTK library, but let's make our own for fun).\n",
    "\n",
    "The data source we'll use as input is a policy document from Thames Coromandel District Council `https://docs.tcdc.govt.nz/store/default/8021091.pdf`. At first glance\n",
    "it has entirely English words in it. Most of them relate to finance-y things. How might this affect the results\n",
    "of training our classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text, tag it\n",
    "taggedWords = getTextAndTagIt(\"thamesTreasury.pdf\", \"english\")\n",
    "\n",
    "# save the tagged text to file\n",
    "with open('englishWords.txt', 'w', encoding='utf8') as f:\n",
    "  for item in taggedWords:\n",
    "    f.write(f\"{item}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get some bilingual text data\n",
    "We would also like to have some text data with a mix of Māori and English words in it\n",
    "that we can test our classifier on. We'll use the function we wrote earlier to get some text from a PDF\n",
    "that includes a mix of reo - the Māori Health Action Plan from Manatū Hauora https://www.health.govt.nz/system/files/documents/publications/whakamaua-maori-health-action-plan-2020-2025-2.pdf (CC-BY).\n",
    "\n",
    "If we want to use these as a test set with any sort of quantitative metrics, we'll need to tag these words too. \n",
    "But for now we'll put that in the too hard basket and just eyeball the results when it comes to applying our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text data, tag it with a junk tag that we won't use.\n",
    "\n",
    "taggedWords = getTextAndTagIt(\"whakamaua-maori-health-action-plan.pdf\",\"no-tag\")\n",
    "\n",
    "# save the text to file\n",
    "with open('mixedWords.txt', 'w', encoding='utf8') as f:\n",
    "  for item in taggedWords:\n",
    "    f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-indigidata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
